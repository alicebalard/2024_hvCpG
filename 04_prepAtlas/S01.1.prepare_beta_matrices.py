#!/usr/bin/env python3
"""
# Prepare Loyfer WGBS Atlas Data
---------------------------------
This script:
 1Ô∏è‚É£ Filters cell/tissue groups with at least 3 samples
 2Ô∏è‚É£ Loads beta files (.beta)
 3Ô∏è‚É£ Builds a CpG-by-sample matrix for each group
 4Ô∏è‚É£ Masks coverage < 10
 5Ô∏è‚É£ Applies logit transform: log2(p / (1 - p)) with clipping
 6Ô∏è‚É£ Saves: (a) matrix, (b) median of per-CpG row SD per data set, (c) lambda per dataset, (d) CpG names

Author: Alice Balard
"""

# üß© Setup

import os
import glob
import numpy as np
import pandas as pd
import re
import h5py
import bottleneck as bn

output_folder = "/home/alice/Documents/Project_hvCpG/10X" ## in cluster "/SAN/ghlab/epigen/Alice/hvCpG_project/data/WGBS_human/AtlasLoyfer/10X"
os.chdir(output_folder)
input_folder = "../betaFiles"

output_file = "all_scaled_matrix.h5"
metadata_file = "sample_metadata.tsv"
output_file_medsd_lambda = "all_medsd_lambda.tsv"

minCov = 10 # We will mask sites for which the coverage is below this

# üìÇ 1Ô∏è‚É£ Read metadata & filter valid groups

meta = pd.read_csv("../SupTab1_Loyfer2023.csv")

# Create composite group
meta["Composite Group"] = meta["Source Tissue"] + " - " + meta["Cell type"]

# Count samples per composite group
group_counts = meta.groupby("Composite Group").size()

# Keep groups with ‚â• 3 samples
valid_groups = group_counts[group_counts >= 3].index.tolist()

print(f"‚úÖ Found {len(valid_groups)} composite groups (Source Tissue + Cell type) with ‚â• 3 samples.")

# Build dict: {group: [sample1, sample2, ...]}
samples_per_group = {
    g: meta.loc[meta["Composite Group"] == g, "Sample name"].tolist()
    for g in valid_groups
}

samples_per_group_short = {
    g: [s.split("-")[-1] for s in samples]
    for g, samples in samples_per_group.items()
}

# üß¨ 2Ô∏è‚É£ Load CpG names

with open("../hg38CpGpos_Loyfer2023.txt") as f:
    cpg_names = [line.strip() for line in f]

print(f"‚úÖ Loaded {len(cpg_names):,} CpG names.")
NR_SITES = len(cpg_names)

# üí° 3Ô∏è‚É£ Helper: Load beta + coverage

def load_beta(path):
    """
    A .beta file is a binary file: NR_SITES rows √ó 2 columns:
      - [0]: # methylated reads (uint8)
      - [1]: total coverage (uint8)
    """
    arr = np.fromfile(path, dtype=np.uint8).reshape((-1, 2))
    meth = arr[:, 0]
    cov = arr[:, 1]
    with np.errstate(divide='ignore', invalid='ignore'):
        beta = np.where(cov == 0, np.nan, meth / cov).astype(np.float32)
    return beta, cov

# üìä 4Ô∏è‚É£ For each group: build matrix, CLIP THEN logit transform (avoid massive issues for large 0s or 1s transformed).
# Save one file for all groups

# Collect all beta files once (outside the loop!)
all_files = glob.glob("../betaFiles/GSM*.hg38.beta")

## Store everything
# Count total number of valid samples first (flat list of all samples)

all_valid_samples = [s for group in samples_per_group_short.values() for s in group]
output_path = os.path.join(output_folder, "all_scaled_matrix.h5")
h5f = h5py.File(output_path, "w")
scaled_dset = h5f.create_dataset(
    "scaled_matrix",
    shape=(NR_SITES, len(all_valid_samples)),
    dtype="float32",
    compression="gzip"
)
sample_names = []
sample_groups = []
sample_idx = 0  # to track sample index across all groups

# To collect per-group stats
all_sample_names = []
all_sample_groups = []
group_medians = {}
group_lambdas = {}

for group, samples in samples_per_group_short.items():
    print(f"üîÑ Processing {group} ({len(samples)} samples)")
    group_start_idx = sample_idx  # mark where this group starts
    for s in samples:
        matches = [fn for fn in all_files if re.search(f"-{s}\\.hg38\\.beta$", fn)]
        if not matches:
            print(f"‚ö†Ô∏è  No beta file found for: {s}")
            continue
        fn = matches[0]
        beta, cov = load_beta(fn)
        if len(beta) != NR_SITES:
            raise ValueError(f"Mismatch: {s} has {len(beta)} CpGs, expected {NR_SITES}")
        ## Clip at 0.01 then logit
        epsilon = 0.01
        beta_clipped = np.clip(beta, epsilon, 1 - epsilon)
        scaled = np.log2(beta_clipped / (1 - beta_clipped)).astype(np.float32)
        ## Mask low coverage sites (we mask but keep the order of CpGs)
        scaled[cov < minCov] = np.nan
        scaled_dset[:, sample_idx] = scaled
        sample_names.append(s.encode())
        sample_groups.append(group.encode())
        all_sample_names.append(s)
        all_sample_groups.append(group)
        sample_idx += 1

    # Extract matrix for this group from the HDF5 dataset
    group_sample_indices = list(range(group_start_idx, sample_idx))
    if len(group_sample_indices) == 0:
        print(f"‚ö†Ô∏è  Skipping {group}: no valid samples")
        continue
    mat = scaled_dset[:, group_sample_indices]
    # Mask CpGs with <3 non-NaNs
    valid_counts = np.sum(~np.isnan(mat), axis=1)
    mat[valid_counts < 3, :] = np.nan

    # ‚úÖ Save masked matrix back to dataset
    scaled_dset[:, group_sample_indices] = mat

    # Compute stats
    row_sds = bn.nanstd(mat, axis=1)
    median_sd = np.nanmedian(row_sds)
    percentile_95 = np.nanpercentile(row_sds, 95)
    lambda_value = percentile_95 / median_sd
    group_medians[group] = median_sd
    group_lambdas[group] = lambda_value
    print(f"‚úÖ {group}: median_sd = {median_sd:.4f}, lambda = {lambda_value:.4f}")

# Finalize HDF5
max_len = max(len(s) for s in sample_names)
dt = f'S{max_len}'
h5f.create_dataset("samples", data=np.array(sample_names, dtype=dt))

max_len = max(len(s) for s in sample_groups)
dt = f'S{max_len}'
h5f.create_dataset("sample_groups", data=np.array(sample_groups, dtype=dt))

h5f.create_dataset("cpg_names", data=np.array(cpg_names, dtype="S"))

h5f.close()
print(f"‚úÖ Saved all samples to: {output_path}")

# Save metadata file
meta_df = pd.DataFrame({
    "sample": all_sample_names,
    "dataset": all_sample_groups
})
meta_df.to_csv(metadata_file, sep="\t", index=False)
print(f"‚úÖ Saved metadata to: {metadata_file}")

# Save SDs and lambdas

# Combine the dictionaries into a DataFrame
df = pd.DataFrame({
    "dataset": list(group_medians.keys()),
    "median_sd": list(group_medians.values()),
    "lambda": [group_lambdas[k] for k in group_medians.keys()]
})

# Save to TSV
df.to_csv(output_file_medsd_lambda, sep="\t", index=False)

print(f"‚úÖ Saved medians and lambdas to TSV: {output_file_medsd_lambda}")

print("\nüéâ All done.")

## 10X with correct clipping, 7th August

##‚úÖ Found 46 composite groups (Source Tissue + Cell type) with ‚â• 3 samples.
##‚úÖ Loaded 29,401,795 CpG names.
##üîÑ Processing Abdominal Subcut. - Adipocytes (3 samples)
##‚úÖ Abdominal Subcut. - Adipocytes: median_sd = 0.6063, lambda = 2.6899
##üîÑ Processing Bladder - Epithelium (5 samples)
##‚úÖ Bladder - Epithelium: median_sd = 1.1999, lambda = 1.8013
##üîÑ Processing Blood - B cells (3 samples)
##‚úÖ Blood - B cells: median_sd = 0.7681, lambda = 2.3146
##üîÑ Processing Blood - Granulocytes (3 samples)
##‚úÖ Blood - Granulocytes: median_sd = 0.7269, lambda = 2.3427
##üîÑ Processing Blood - Monocytes (3 samples)
##‚úÖ Blood - Monocytes: median_sd = 0.8485, lambda = 2.1827
##üîÑ Processing Blood - NK (3 samples)
##‚úÖ Blood - NK: median_sd = 0.8558, lambda = 2.2026
##üîÑ Processing Blood - T central memory CD4 (3 samples)
##‚úÖ Blood - T central memory CD4: median_sd = 0.6959, lambda = 2.5560
##üîÑ Processing Blood - T cytotoxic (CD8+) cells (3 samples)
##‚úÖ Blood - T cytotoxic (CD8+) cells: median_sd = 0.7793, lambda = 2.2730
##üîÑ Processing Blood - T effector cell CD8 (3 samples)
##‚úÖ Blood - T effector cell CD8: median_sd = 0.7139, lambda = 2.5509
##üîÑ Processing Blood - T effector memory CD4 (3 samples)
##‚úÖ Blood - T effector memory CD4: median_sd = 0.6629, lambda = 2.6953
##üîÑ Processing Blood - T helper(CD4+) cells (3 samples)
##‚úÖ Blood - T helper(CD4+) cells: median_sd = 0.7060, lambda = 2.4016
##üîÑ Processing Bone marrow - Erythrocyte progenitors (3 samples)
##‚úÖ Bone marrow - Erythrocyte progenitors: median_sd = 0.4534, lambda = 2.8974
##üîÑ Processing Brain - Neuronal (10 samples)
##‚úÖ Brain - Neuronal: median_sd = 1.2014, lambda = 1.8241
##üîÑ Processing Brain - Oligodendrocytes (4 samples)
##‚úÖ Brain - Oligodendrocytes: median_sd = 0.8917, lambda = 1.9653
##üîÑ Processing Breast - Basal epithelial (4 samples)
##‚úÖ Breast - Basal epithelial: median_sd = 1.0155, lambda = 1.8505
##üîÑ Processing Breast - Luminal epithelial (3 samples)
##‚úÖ Breast - Luminal epithelial: median_sd = 0.8777, lambda = 2.1080
##üîÑ Processing Colon - Endocrine (3 samples)
##‚úÖ Colon - Endocrine: median_sd = 0.9731, lambda = 2.0978
##üîÑ Processing Colon - Epithelium (5 samples)
##‚úÖ Colon - Epithelium: median_sd = 0.9189, lambda = 1.9414
##üîÑ Processing Endometrium - Epithelium (3 samples)
##‚úÖ Endometrium - Epithelium: median_sd = 0.7785, lambda = 2.3460
##üîÑ Processing Fallopien tubes - Epithelium (3 samples)
##‚úÖ Fallopien tubes - Epithelium: median_sd = 0.7369, lambda = 2.2802
##üîÑ Processing Gastric antrum - Epithelium (3 samples)
##‚úÖ Gastric antrum - Epithelium: median_sd = 0.6390, lambda = 2.5203
##üîÑ Processing Gastric body - Epithelium (3 samples)
##‚úÖ Gastric body - Epithelium: median_sd = 0.6542, lambda = 2.4930
##üîÑ Processing Gastric fundus - Epithelium (3 samples)
##‚úÖ Gastric fundus - Epithelium: median_sd = 0.6133, lambda = 2.5540
##üîÑ Processing Heart - Cardiomyocyte (4 samples)
##‚úÖ Heart - Cardiomyocyte: median_sd = 0.8948, lambda = 2.0003
##üîÑ Processing Heart - Fibroblast (4 samples)
##‚úÖ Heart - Fibroblast: median_sd = 0.7425, lambda = 2.4008
##üîÑ Processing Kidney glomerular - Endothelium (3 samples)
##‚úÖ Kidney glomerular - Endothelium: median_sd = 0.7020, lambda = 2.3966
##üîÑ Processing Kidney glomerular - Podocyte (3 samples)
##‚úÖ Kidney glomerular - Podocyte: median_sd = 0.7658, lambda = 2.2720
##üîÑ Processing Kidney tubular - Endothelium (3 samples)
##‚úÖ Kidney tubular - Endothelium: median_sd = 0.7441, lambda = 2.4076
##üîÑ Processing Kidney tubular - Epithelium (3 samples)
##‚úÖ Kidney tubular - Epithelium: median_sd = 0.8099, lambda = 2.3028
##üîÑ Processing Liver - Hepatocyte (6 samples)
##‚úÖ Liver - Hepatocyte: median_sd = 0.9215, lambda = 1.9534
##üîÑ Processing Lung alveolar - Endothelium (3 samples)
##‚úÖ Lung alveolar - Endothelium: median_sd = 0.7575, lambda = 2.2733
##üîÑ Processing Lung alveolar - Epithelium (3 samples)
##‚úÖ Lung alveolar - Epithelium: median_sd = 0.6348, lambda = 2.4780
##üîÑ Processing Lung bronchus - Epithelium (3 samples)
##‚úÖ Lung bronchus - Epithelium: median_sd = 0.6711, lambda = 2.4284
##üîÑ Processing Lung interstitial - Macrophages (3 samples)
##‚úÖ Lung interstitial - Macrophages: median_sd = 0.7719, lambda = 2.2833
##üîÑ Processing Pancreas - Acinar (4 samples)
##‚úÖ Pancreas - Acinar: median_sd = 0.7151, lambda = 2.3649
##üîÑ Processing Pancreas - Alpha (3 samples)
##‚úÖ Pancreas - Alpha: median_sd = 0.6694, lambda = 2.5248
##üîÑ Processing Pancreas - Beta (3 samples)
##‚úÖ Pancreas - Beta: median_sd = 0.7447, lambda = 2.4184
##üîÑ Processing Pancreas - Delta (3 samples)
##‚úÖ Pancreas - Delta: median_sd = 0.7897, lambda = 2.3703
##üîÑ Processing Pancreas - Duct (4 samples)
##‚úÖ Pancreas - Duct: median_sd = 0.9136, lambda = 2.0156
##üîÑ Processing Pancreas - Endothelium (4 samples)
##‚úÖ Pancreas - Endothelium: median_sd = 0.8505, lambda = 2.1393
##üîÑ Processing Prostate - Epithelium (4 samples)
##‚úÖ Prostate - Epithelium: median_sd = 0.9489, lambda = 1.9747
##üîÑ Processing Small intestine - Epithelium (3 samples)
##‚úÖ Small intestine - Epithelium: median_sd = 0.7015, lambda = 2.4121
##üîÑ Processing Thyroid - Epithelium (3 samples)
##‚úÖ Thyroid - Epithelium: median_sd = 0.7273, lambda = 2.3525
##üîÑ Processing Tongue - Epithelium (4 samples)
##‚úÖ Tongue - Epithelium: median_sd = 0.9290, lambda = 1.9847
##üîÑ Processing Tonsil palatine - Epithelium (3 samples)
##‚úÖ Tonsil palatine - Epithelium: median_sd = 0.6162, lambda = 2.6465
##üîÑ Processing Vascular saphenous - Endothelium (3 samples)
##‚úÖ Vascular saphenous - Endothelium: median_sd = 0.7071, lambda = 2.3832
##‚úÖ Saved all samples to: /home/alice/Documents/Project_hvCpG/10X/all_scaled_matrix.h5
##‚úÖ Saved metadata to: sample_metadata.tsv
##‚úÖ Saved medians and lambdas to TSV: all_medsd_lambda.tsv
##
##üéâ All done.
