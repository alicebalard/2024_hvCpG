offsets[, cum_offset := c(0, head(cumsum(as.numeric(max_pos)), -1))]
dt <- merge(dt, offsets[, .(chr, cum_offset)], by = "chr", all.x = TRUE, sort = FALSE)
# Convert to integer/numeric if not already
dt[, cum_offset := as.numeric(cum_offset)]
dt[, pos2 := pos + cum_offset]
return(dt)
}
system.time(Atlas_dt <- prepAtlasdt())
if (exists("doIprepAtlas") && isTRUE(doIprepAtlas)) {
stop("stop here to only prepare atlas_dt")
}
# Compute chromosome centers for x-axis labeling
df2 <- Atlas_dt[, .(center = mean(range(pos2, na.rm = TRUE))), by = chr]
df2 <- merge(data.frame(chr = factor(c(1:22, "X", "Y", "M"), levels=as.character(c(1:22, "X", "Y", "M")))),
df2, by = "chr", all.x = TRUE, sort = TRUE)
df2 <- na.omit(df2)
# Compute chromosome boundaries
df_bounds <- Atlas_dt[, .(min_pos = min(pos2, na.rm = TRUE),
max_pos = max(pos2, na.rm = TRUE)), by = chr]
# Midpoints between chromosomes = where to draw dotted lines
df_bounds[, next_start := data.table::shift(min_pos, n = 1, type = "lead")]
vlines <- df_bounds[!is.na(next_start), .(xintercept = (max_pos + next_start)/2)]
plot <- ggplot() +
# background cloud
geom_point_rast(data = Atlas_dt[is.na(group)],
aes(x = pos2, y = alpha),
color = "black", size = 0.01, alpha = 0.01, raster.dpi = 72) +
# hvCpG highlights
geom_point(data = Atlas_dt[group == "hvCpG_Derakhshan"],
aes(x = pos2, y = alpha),
color = "#DC3220", size = 1, alpha = 0.7) +
# mQTL controls highlights
geom_point(data = Atlas_dt[group == "mQTLcontrols"],
aes(x = pos2, y = alpha),
color = "#005AB5", size = 1, alpha = 0.7) +
# Add dotted separators
geom_vline(data = vlines, aes(xintercept = xintercept),
linetype = 3, color = "grey60") +
theme_classic() + theme(legend.position = "none") +
scale_x_continuous(breaks = df2$center, labels = as.character(df2$chr), expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
labs(x = "Chromosome", y = "Probability of being a hvCpG")+
theme_minimal(base_size = 14)
# Save as PDF â€” rasterization improves performance and file size
CairoPDF(here("05_hvCpGalgorithm/figures/ManhattanAlphaPlot_previoushvCpGplotted_atlas.pdf"), width = 15, height = 3)
print(plot)
dev.off()
## Without the layer of previous hvCpG and controls plotted:
plot <- ggplot() +
geom_point_rast(data = Atlas_dt,
aes(x = pos2, y = alpha),
color = "black", size = 0.01, alpha = 0.01, raster.dpi = 72) +
# Add dotted separators
geom_vline(data = vlines, aes(xintercept = xintercept),
linetype = 3, color = "grey60") +
theme_classic() + theme(legend.position = "none") +
scale_x_continuous(breaks = df2$center, labels = as.character(df2$chr), expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
labs(x = "Chromosome", y = "Probability of being a hvCpG")+
theme_minimal(base_size = 14)
# Save as PDF â€” rasterization improves performance and file size
CairoPDF(here("05_hvCpGalgorithm/figures/ManhattanAlphaPlot_atlas.pdf"), width = 15, height = 3)
print(plot)
dev.off()
DerakhshanhvCpGs_hg38
data <- read.table(here("03_prepDatasetsMaria/cistrans_GoDMC_hvCpG_matched_control.txt"), header = T)
head(data)
match(data$hvCpG_name, DerakhshanhvCpGs_hg38)
data$hvCpG_name
dico$CpG
match(data$hvCpG_name, dico$CpG)
dico$chrpos_hg38[match(data$hvCpG_name, dico$CpG)]
y = dico$chrpos_hg38[match(data$controlCpG_name, dico$CpG)]
#
x = dico$chrpos_hg38[match(data$hvCpG_name, dico$CpG)]
y = dico$chrpos_hg38[match(data$controlCpG_name, dico$CpG)]
# Build mapping from hvCpG -> control
pairs <- data.frame(
hvCpG = x,
control = y,
stringsAsFactors = FALSE
)
# Merge hvCpG alphas
res <- Atlas_dt[!is.na(group)]
hv_alpha <- res[, c("name", "alpha")]
colnames(hv_alpha) <- c("hvCpG", "alpha_hvCpG")
# Merge control alphas
ctrl_alpha <- res[, c("name", "alpha")]
colnames(ctrl_alpha) <- c("control", "alpha_control")
# Join everything
merged <- pairs %>%
left_join(hv_alpha, by = "hvCpG") %>%
left_join(ctrl_alpha, by = "control") %>%
mutate(diffAlpha=alpha_hvCpG-alpha_control)
merged <- merged %>%
mutate(chr = str_extract(hvCpG, "^chr[0-9XYM]+"))%>%
filter(!is.na(diffAlpha))
ggplot(merged, aes(x="diff", y=diffAlpha))+
geom_jitter(data=merged[merged$diffAlpha>=0,], col="black", alpha=.5)+
geom_jitter(data=merged[merged$diffAlpha<0,], fill="yellow",col="black",pch=21, alpha=.5)+
geom_violin(width=.5, fill = "grey", alpha=.8) +
geom_boxplot(width=0.1, color="black", fill = "grey", alpha=0.8) +
theme_minimal(base_size = 14)+
theme(axis.title.x = element_blank(), axis.text.x = element_blank(), title = element_text(size=10))+
ggtitle("P(hvCpG) minus P(matching control) in atlas")+
ylab("Difference of probability")
pdf(here("05_hvCpGalgorithm/figures/DifferenceOfProbabilityForhvCpG-matching_controlInAtlas.pdf"),
width = 4, height = 5)
ggplot(merged, aes(x="diff", y=diffAlpha))+
geom_jitter(data=merged[merged$diffAlpha>=0,], col="black", alpha=.5)+
geom_jitter(data=merged[merged$diffAlpha<0,], fill="yellow",col="black",pch=21, alpha=.5)+
geom_violin(width=.5, fill = "grey", alpha=.8) +
geom_boxplot(width=0.1, color="black", fill = "grey", alpha=0.8) +
theme_minimal(base_size = 14)+
theme(axis.title.x = element_blank(), axis.text.x = element_blank(), title = element_text(size=10))+
ggtitle("P(hvCpG) minus P(matching control) in atlas")+
ylab("Difference of probability")
dev.off()
ggplot(merged, aes(x="diff", y=diffAlpha))+
geom_jitter(data=merged[merged$diffAlpha>=0,], col="black", alpha=.5)+
geom_jitter(data=merged[merged$diffAlpha<0,], fill="yellow",col="black",pch=21, alpha=.5)+
geom_violin(width=.5, fill = "grey", alpha=.8) +
geom_boxplot(width=0.1, color="black", fill = "grey", alpha=0.8) +
theme_minimal(base_size = 14)+
theme(axis.title.x = element_blank(), axis.text.x = element_blank(), title = element_text(size=10))+
ggtitle("P(hvCpG) minus P(matching control) in atlas")+
ylab("Difference of probability") +
facet_grid(.~chr)
##################################
## Save names high alpha points ##
##################################
table(Atlas_dt$alpha >= 0.7)
## Map on arrays
matches <- match(
x = unlist(Atlas_dt[Atlas_dt$alpha >= 0.7, "name"]),
table = dico$chrpos_hg38
)
highAlphaPos <- dico[na.omit(matches), ]
table(highAlphaPos$array)
saveRDS(highAlphaPos, here("05_hvCpGalgorithm/runAlgo_myDatasets/exploreResults/fetalSIV/highAlphaPos_atlas0.7.RDS"))
highAlphaPos
##########################################
## What are the gaps in Manhattan plot? ##
# Compute the gap between consecutive CpGs on the same chromosome
Atlas_dt[, gap := pos - data.table::shift(pos), by = chr]
# Identify large gaps (>= 500k bp)
gaps_dt <- Atlas_dt[gap >= 500000, .(
chr,
gap_start = data.table::shift(pos),
gap_end = pos,
gap_size = gap
)]
# Drop first NA (since shift introduces one per chromosome)
gaps_dt[!is.na(gap_size)]
ggplot() +
geom_point(data = Atlas_dt[Atlas_dt$chr == "M",],
aes(x = pos2, y = alpha),
color = "black", size = 1, alpha = .5)+
theme_classic() + theme(legend.position = "none") +
scale_x_continuous(breaks = df2[df2$chr == "M","center"],
labels = as.character(df2[df2$chr == "M","chr"]), expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0), limits = c(0,.1)) +
labs(x = "Chromosome", y = "Probability of being a hvCpG")+
theme_minimal(base_size = 14)
###################################
## Y chromosome DNAm variability ##
###################################
ggplot() +
geom_point(data = Atlas_dt[Atlas_dt$chr == "Y",],
aes(x = start_pos, y = alpha),
color = "black", size = 1, alpha = .5)+
theme_classic() + theme(legend.position = "none") +
geom_hline(yintercept = .7, linetype = 3)+
scale_y_continuous(expand = c(0, 0)) +
labs(x = "Chromosome", y = "Probability of being a hvCpG")+
theme_minimal(base_size = 14)
###################################
## Y chromosome DNAm variability ##
###################################
ggplot() +
geom_point(data = Atlas_dt[Atlas_dt$chr == "Y",],
aes(x = pos, y = alpha),
color = "black", size = 1, alpha = .5)+
theme_classic() + theme(legend.position = "none") +
geom_hline(yintercept = .7, linetype = 3)+
scale_y_continuous(expand = c(0, 0)) +
labs(x = "Chromosome", y = "Probability of being a hvCpG")+
theme_minimal(base_size = 14)
###################################
## Y chromosome DNAm variability ##
###################################
ggplot() +
geom_point(data = Atlas_dt[Atlas_dt$chr == "Y",],
aes(x = pos2, y = alpha),
color = "black", size = 1, alpha = .5)+
theme_classic() + theme(legend.position = "none") +
geom_hline(yintercept = .7, linetype = 3)+
scale_y_continuous(expand = c(0, 0)) +
labs(x = "Chromosome", y = "Probability of being a hvCpG")+
theme_minimal(base_size = 14)
###################################
## Y chromosome DNAm variability ##
###################################
ggplot() +
geom_point(data = Atlas_dt[Atlas_dt$chr == "Y",],
aes(x = pos2, y = alpha),
color = "black", size = 1, alpha = .5)+
theme_classic() + theme(legend.position = "none") +
geom_hline(yintercept = .7, linetype = 3)+
scale_x_continuous(breaks = df2[df2$chr == "Y","center"],
labels = as.character(df2[df2$chr == "Y","chr"]), expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
labs(x = "Chromosome", y = "Probability of being a hvCpG")+
theme_minimal(base_size = 14)
ggplot() +
geom_point(data = Atlas_dt[Atlas_dt$chr == "M",],
aes(x = pos2, y = alpha),
color = "black", size = 1, alpha = .5)+
theme_classic() + theme(legend.position = "none") +
scale_x_continuous(breaks = df2[df2$chr == "M","center"],
labels = as.character(df2[df2$chr == "M","chr"]), expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0), limits = c(0,.1)) +
labs(x = "Chromosome", y = "Probability of being a hvCpG")+
theme_minimal(base_size = 14)
###################################
## Y chromosome DNAm variability ##
###################################
ggplot() +
geom_point(data = Atlas_dt[Atlas_dt$chr == "Y",],
aes(x = pos2, y = alpha),
color = "black", size = 1, alpha = .5)+
theme_classic() + theme(legend.position = "none") +
geom_hline(yintercept = .7, linetype = 3)+
scale_x_continuous(breaks = df2[df2$chr == "Y","center"],
labels = as.character(df2[df2$chr == "Y","chr"]), expand = c(0, 0)) +
scale_y_continuous(expand = c(0, 0)) +
labs(x = "Chromosome", y = "Probability of being a hvCpG")+
theme_minimal(base_size = 14)
Atlas_dt[Atlas_dt$chr == "Y" & Atlas_dt$alpha > 0.7,]
##############
threshold=0.7#
# Filter valid rows
dt_clean <- Atlas_dt[!is.na(start_pos) & !is.na(end_pos)]
# Filter valid rows
dt_clean <- Atlas_dt[!is.na(pos)]
rm(Atlas_dt)
##############
Atlas_dt <- dt_clean
rm(dt_clean)
# Create GRanges
gr_cpg <- GRanges(
seqnames = paste0("chr", Atlas_dt$chr),
ranges = IRanges(start = Atlas_dt$start_pos, end = Atlas_dt$end_pos),
alpha = Atlas_dt$alpha
)
# Import bed file
bed_features <- genomation::readTranscriptFeatures(
"~/Documents/Project_hvCpG/hg38_GENCODE_V47.bed")
# annotate CpGs with high alpha (>threshold):
anno_result_highalpha <- genomation::annotateWithGeneParts(
target = gr_cpg[!is.na(mcols(gr_cpg)$alpha) & mcols(gr_cpg)$alpha > threshold],
feature = bed_features)
# Create GRanges
gr_cpg <- GRanges(
seqnames = paste0("chr", Atlas_dt$chr),
ranges = IRanges(start = Atlas_dt$pos, end = Atlas_dt$pos),
alpha = Atlas_dt$alpha
)
# Import bed file
bed_features <- genomation::readTranscriptFeatures(
"~/Documents/Project_hvCpG/hg38_GENCODE_V47.bed")
# annotate CpGs with high alpha (>threshold):
anno_result_highalpha <- genomation::annotateWithGeneParts(
target = gr_cpg[!is.na(mcols(gr_cpg)$alpha) & mcols(gr_cpg)$alpha > threshold],
feature = bed_features)
# annotate CpGs with low alpha (<=threshold):
anno_result_lowalpha <- genomation::annotateWithGeneParts(
target = gr_cpg[!is.na(mcols(gr_cpg)$alpha) & mcols(gr_cpg)$alpha <= threshold],
feature = bed_features)
# Percentages from annotations
low_anno <- anno_result_lowalpha@precedence
high_anno <- anno_result_highalpha@precedence
## Convert percentages to counts
N_low <- nrow(Atlas_dt[alpha <= threshold])
N_high <- nrow(Atlas_dt[alpha > threshold])
# Reconstruct counts from percentages
count_low <- round(low_anno / 100 * N_low)
count_high <- round(high_anno / 100 * N_high)
## Build contingency table
contingency <- rbind(
LowAlpha = count_low,
HighAlpha = count_high
)
print(contingency)
#            promoter    exon   intron intergenic
# LowAlpha   3112722 1179458 12071239    4987877
# HighAlpha    53647   21547   343090     166446
##  Perform chi-squared test
chisq.test(contingency)
# Pearson's Chi-squared test
# data:  contingency
################
## Barplot ##
df_plot <- as.data.frame(contingency) %>%
tibble::rownames_to_column("AlphaGroup") %>%
tidyr::pivot_longer(-AlphaGroup, names_to = "Region", values_to = "Count") %>%
group_by(AlphaGroup) %>%
mutate(Percent = Count / sum(Count) * 100)
pdf(here("05_hvCpGalgorithm/figures/barplotFeaturesLowHighAlpha.pdf"), width = 5, height = 4)
ggplot(df_plot, aes(x=Region, y=Percent, fill = AlphaGroup))+
geom_bar(position="dodge", stat="identity") +
theme_minimal(base_size = 14)+
scale_fill_manual(
values = c("red", "skyblue"),
name = "p(hv)",      # optional
labels = c(">70%", "<=70%")   # new names for legend keys
) +
theme(axis.title.x = element_blank())
dev.off()
rm(anno_result_highalpha, anno_result_lowalpha)
rm(anno_result_highalpha, anno_result_lowalpha)
source(here("05_hvCpGalgorithm/runAlgo_myDatasets/exploreResults/prepPreviousSIV.R"))
retestAnnot = FALSE
retestAnnot = FALSE
if (retestAnnot){
##############
threshold=0.7#
##############
# Create GRanges
gr_cpg <- GRanges(
seqnames = paste0("chr", Atlas_dt$chr),
ranges = IRanges(start = Atlas_dt$pos, end = Atlas_dt$pos),
alpha = Atlas_dt$alpha
)
# Import bed file
bed_features <- genomation::readTranscriptFeatures(
"~/Documents/Project_hvCpG/hg38_GENCODE_V47.bed")
# annotate CpGs with high alpha (>threshold):
anno_result_highalpha <- genomation::annotateWithGeneParts(
target = gr_cpg[!is.na(mcols(gr_cpg)$alpha) & mcols(gr_cpg)$alpha > threshold],
feature = bed_features)
# annotate CpGs with low alpha (<=threshold):
anno_result_lowalpha <- genomation::annotateWithGeneParts(
target = gr_cpg[!is.na(mcols(gr_cpg)$alpha) & mcols(gr_cpg)$alpha <= threshold],
feature = bed_features)
# Percentages from annotations
low_anno <- anno_result_lowalpha@precedence
high_anno <- anno_result_highalpha@precedence
## Convert percentages to counts
N_low <- nrow(Atlas_dt[alpha <= threshold])
N_high <- nrow(Atlas_dt[alpha > threshold])
# Reconstruct counts from percentages
count_low <- round(low_anno / 100 * N_low)
count_high <- round(high_anno / 100 * N_high)
## Build contingency table
contingency <- rbind(
LowAlpha = count_low,
HighAlpha = count_high
)
print(contingency)
#            promoter    exon   intron intergenic
# LowAlpha   3263097 1236235 12641037    5195054
# HighAlpha    68158   26465   404505     201475
##  Perform chi-squared test
chisq.test(contingency)
# Pearson's Chi-squared test
# data:  contingency
# X-squared = 23940, df = 3, p-value < 2.2e-16
# promoters and exons are depleted, and intergenic and introns are enriched, in hypervariable CpGs
################
## Barplot ##
df_plot <- as.data.frame(contingency) %>%
tibble::rownames_to_column("AlphaGroup") %>%
tidyr::pivot_longer(-AlphaGroup, names_to = "Region", values_to = "Count") %>%
group_by(AlphaGroup) %>%
mutate(Percent = Count / sum(Count) * 100)
pdf(here("05_hvCpGalgorithm/figures/barplotFeaturesLowHighAlpha.pdf"), width = 5, height = 4)
ggplot(df_plot, aes(x=Region, y=Percent, fill = AlphaGroup))+
geom_bar(position="dodge", stat="identity") +
theme_minimal(base_size = 14)+
scale_fill_manual(
values = c("red", "skyblue"),
name = "p(hv)",      # optional
labels = c(">70%", "<=70%")   # new names for legend keys
) +
theme(axis.title.x = element_blank())
dev.off()
rm(anno_result_highalpha, anno_result_lowalpha)
}
highAlphaPos
#################################################
## Plot results of algorithm ran on atlas data ##
#################################################
library(here)
source(here("05_hvCpGalgorithm", "quiet_library.R"))
## Load array results
resArray <- readRDS(here("05_hvCpGalgorithm/dataOut/resArray.RDS"))
## Add previous MEs including Maria's results
source(here("05_hvCpGalgorithm/runAlgo_myDatasets/exploreResults/prepPreviousSIV.R"))
## This code does:
### I. Histogram of coverage across datasets
### II. Load data & Manhattan plot
### III. Test enrichment of features for high alpha
### IV. Test for enrichment in other putative MEs for hvCpGs with alpha > threshold
## Data in WGBS atlas:
## from the CS cluster: sample_groups <- h5read("/SAN/ghlab/epigen/Alice/hvCpG_project/data/WGBS_human/AtlasLoyfer/10X/all_matrix_noscale.h5","sample_groups")
sample_groups <- readRDS(here("05_hvCpGalgorithm/runAlgo_myDatasets/Atlas/sample_groups.RDS"))
ggplot(data.frame(table(sample_groups)), aes(x = Freq)) +
geom_histogram(bins = 100, fill = "steelblue", color = "white") +
theme_minimal(base_size = 14) +
labs(
title = "Distribution of number of samples per dataset",
x = "Number of samples",
y = "Count of datasets"
) +
scale_x_continuous(breaks = seq(0, 10, by = 1))
table(sample_groups)
##############################################
## I. Histogram of coverage across datasets ##
##############################################
t5 <- read.table(here("04_prepAtlas/CpG_coverage_freqtable5X.tsv"), header = T)
t10 <- read.table(here("04_prepAtlas/CpG_coverage_freqtable10X.tsv"), header = T)
# Add coverage type label
t5$coverage <- "â‰¥5"
t10$coverage <- "â‰¥10"
# Combine into one data.table
t_combined <- rbind(t5, t10)
# Filter out CpGs with zero dataset coverage if needed
t_combined <- t_combined[t_combined$datasets_covered_in > 0, ]
t_combined <- t_combined %>% group_by(coverage) %>%
dplyr::arrange(-dplyr::row_number(datasets_covered_in)) %>%
mutate(nCpGcum = cumsum(num_CpGs))
options(scipen=0)
# Plot
pdf(here("05_hvCpGalgorithm", "figures", "freqCpGperdataset.pdf"), width = 14, height = 4)
ggplot(t_combined, aes(x = as.factor(datasets_covered_in), y = nCpGcum, fill = coverage)) +
geom_col(position = "dodge") +
scale_y_continuous(
breaks = seq(0, 100000000, by = 10000000),  # 10 million steps
labels = label_number(scale = 1e-6, suffix = "M")
) +  scale_fill_manual(values = c("â‰¥5" = "steelblue", "â‰¥10" = "firebrick")) +
labs(title = "Nbr of CpG covered across X or more datasets",
x = ">= X datasets",
y = "Number of CpGs with â‰¥3 samples covered",
fill = "Coverage threshold") +
theme_minimal(base_size = 14) +
guides(fill = guide_legend(position = "inside")) +
theme(legend.position.inside = c(.2,.5),
legend.box = "horizontal",
legend.background = element_rect(fill = "white", color = "black", linewidth = 0.4),
legend.key = element_rect(fill = "white", color = NA))
dev.off()
t_combined[t_combined$coverage %in% "â‰¥10" &  t_combined$datasets_covered_in %in% 46,"num_CpGs"] /
sum(t_combined[t_combined$coverage %in% "â‰¥10","num_CpGs"])
## 84% of all CpGs (23/27.5M) are covered in 46 cell types
rm(t_combined, t5, t10)
####################################
## II. Load data & Manhattan plot ##
####################################
prepAtlasdt <- function(){
# Define parent folder containing all "Atlas_batchXXX" folders
parent_dir <- here("05_hvCpGalgorithm/resultsDir/Atlas/Atlas10X/")
# Get list of relevant RData files
rdata_files <- dir(parent_dir, pattern = "results_Atlas10X_[0-9]+CpGs_0_8p0_0_65p1\\.RData$",
recursive = TRUE, full.names = TRUE)
## Check if all batches have ran
length(rdata_files) == 231
all_cpg_values <- numeric()
pb <- progress_bar$new(total = length(rdata_files), format = "ðŸ“¦ :current/:total [:bar] :percent")
for (file in rdata_files) {
e <- new.env()
load(file, envir = e)
obj <- e[[ls(e)[1]]]
if (is.matrix(obj)) obj <- obj[, 1]
all_cpg_values <- c(all_cpg_values, obj)
pb$tick()
}
# Create data.table from named vector
dt <- data.table(
name =   sub("-[0-9]+$", "", names(all_cpg_values)), # just keep the C position instead of C + 1
alpha = as.numeric(all_cpg_values)
)
rm(e, pb, all_cpg_values, obj, file, parent_dir, rdata_files)
#######################################################################
# Parse "chr_pos" in name into chr, start_pos, end_pos. NB: takes a couple of minutes
dt[, c("chr", "pos") := tstrsplit(name, "_", fixed = TRUE)]
# Convert to integer/numeric if not already
dt[, pos := as.integer(pos)]
## Check chromosomes present:
message("Chromosomes in the dataset:")
table(unique(dt$chr))
# Convert chr from "chrN" to  factor
dt[, chr := sub("chr", "", chr)]
dt[, chr := factor(chr, levels = as.character(c(1:22, "X", "Y", "M")))]
## Check chromosomes order:
message("Chromosomes in the dataset:")
table(unique(dt$chr))
## Mark group membership in dt
dt[, group := NA_character_]
dt[name %in% DerakhshanhvCpGs_hg38, group := "hvCpG_Derakhshan"]
dt[name %in% mQTLcontrols_hg38, group := "mQTLcontrols"]
# Compute cumulative position offsets for Manhattan plot
setorder(dt, chr, pos)
offsets <- dt[, .(max_pos = max(pos, na.rm = TRUE)), by = chr]
offsets[, cum_offset := c(0, head(cumsum(as.numeric(max_pos)), -1))]
dt <- merge(dt, offsets[, .(chr, cum_offset)], by = "chr", all.x = TRUE, sort = FALSE)
# Convert to integer/numeric if not already
dt[, cum_offset := as.numeric(cum_offset)]
dt[, pos2 := pos + cum_offset]
return(dt)
}
system.time(Atlas_dt <- prepAtlasdt())
