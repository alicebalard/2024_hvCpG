---
title: "hvCpG_BayesAlgo_exploration"
author: "Alice Balard"
date: '`r Sys.Date()`'
output: html_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
invisible(lapply(
  c("dplyr", "data.table", "matrixStats", "ggplot2", "reshape2",
    "ggrepel", "pROC", "stringr", "tibble", "viridis", "ggridges"),
  function(pkg) suppressPackageStartupMessages(library(pkg, character.only = TRUE))
))
```

# Data prep 

```{r}
##########################################################################################
## LSHTM: Maria’s data that she used for the hvCpG paper can be accessed from ing-p5 here:
# /mnt/old_user_accounts/p3/maria/PhD/Data/datasets/
#   
# Her hvCpG scripts are here:
# /mnt/old_user_accounts/p3/maria/PhD/Projects/hvCpGs/Scripts/

## Load results of Maria for hvCpG
Marias_hvCpGs <- read.csv("~/2024_hvCpG/03_prepDatasetsMaria/Derakhshan2022_ST5_hvCpG.txt")

## Recreate Maria's datasets
folder1 <- normalizePath("/mnt/old_user_accounts/p3/maria/PhD/Data/datasets/GEO/BMIQ + 10 PCs + age + sex OUTLIERS REMOVED/")
rds_files1 <- list.files(path = folder1, pattern = "\\.RDS$", full.names = TRUE)

# Read all .rds files into a list and convert each to a matrix
rds_list_mat1 <- lapply(rds_files1, function(file) {as.matrix(readRDS(file))})
## Name the list elements by file names (without extensions)
names(rds_list_mat1) <- gsub("\\.RDS$", "", basename(rds_files1))

rds_list_mat2 <- readRDS("/mnt/old_user_accounts/p3/maria/PhD/Data/datasets/TCGA/TCGA_BMIQ_age_sex_PC_adjusted_OUTLIERS_REMOVED_round2.RDS")
rds_list_mat2 <- lapply(rds_list_mat2, as.matrix)

rds_list_mat <- c(rds_list_mat1, rds_list_mat2) ; rm(rds_list_mat1, rds_list_mat2)

# Keep only the array background (covered in 15 datasets out of 30)
all_cpgs <- unlist(lapply(rds_list_mat, rownames))
cpg_counts <- table(all_cpgs)
common_cpgs <- names(cpg_counts[cpg_counts >= 15])

rds_list_mat <- lapply(rds_list_mat, function(mat) {
  mat[rownames(mat) %in% common_cpgs, ]
})

## Load mQTL-matched controls
cistrans_GoDMC_hvCpG_matched_control <- 
  read.table("~/2024_hvCpG/03_prepDatasetsMaria/cistrans_GoDMC_hvCpG_matched_control.txt", header = T)

## Load cpgnames (all dpg covered after filtration)
cpgnames <- read.table("~/arraysh5files/sorted_common_cpgs.txt")$V1

## Check if I'm consistent
table(cpgnames %in% common_cpgs) ## PERFECT

sub_cistrans_GoDMC_hvCpG_matched_control <- cistrans_GoDMC_hvCpG_matched_control[
  cistrans_GoDMC_hvCpG_matched_control$hvCpG_name %in% cpgnames &
    cistrans_GoDMC_hvCpG_matched_control$controlCpG_name %in% cpgnames,]

rm(common_cpgs, cpg_counts,all_cpgs, folder1, rds_files1, cistrans_GoDMC_hvCpG_matched_control)
```

# Reproduce Maria’s results
Maria’s paper: We defined an hvCpG in the following way:

1. in 65% of datasets in which the CpG is covered (following quality control), it has methylation variance in the top 5% of all (non-removed) CpGs.
2. is covered in at least 15 of the 30 datasets.

```{r Maria}
## Within each dataset, calculate the CpGs variance, and keep the top 5%
top5pcvar <- lapply(rds_list_mat, function(mat) {
  # Step 1: Calculate row variances
  row_variances = rowVars(mat, na.rm = T)
  df = data.frame(var=row_variances, cpg=names(row_variances))
  # Step 2
  top = top_n(df, as.integer(0.05*nrow(df)), var) ## slightly different than quantile cause keep ties
  return(top)
})

## CpGs in the top 5% variance:
cpg_counts_top <- table(unlist(lapply(top5pcvar, rownames))) %>%
  data.frame() %>% dplyr::rename("cpgs"="Var1", "all_cpgs_top5pc"="Freq")

## all covered CpGs:
cpg_counts <- table(unlist(lapply(rds_list_mat, rownames))) %>%
  data.frame() %>% dplyr::rename("cpgs"="Var1", "all_cpgs"="Freq")

## Both:
cpg_counts_full <- merge(cpg_counts, cpg_counts_top, all.x = T)
rm(cpg_counts, cpg_counts_top)

## in 65% of datasets in which the CpG is covered (following quality control), it has methylation variance in the top 5% of all (non-removed) CpGs:
## rounding, to mimick Maria's approach
hvCpGs_repro_maria <- na.omit(cpg_counts_full[round(cpg_counts_full$all_cpgs_top5pc/cpg_counts_full$all_cpgs, 2) >= 0.65,])
```

Maria detected `r length(Marias_hvCpGs$CpG)` hvCpGs. I detected `r length(hvCpGs_repro_maria$cpgs)` hvCpGs.
We both have `r length(intersect(hvCpGs_repro_maria$cpgs, Marias_hvCpGs$CpG))` hvCpGs in common.

# Identify hvCpGs based on a sd multiplicative factor lambda

The proportion of CpGs than Maria found hvCpGs is p(hvCpG) = `r round(4143/406306, 4)*100`%.

## Calculate lambda 

Within each dataset k, calculate the median sd of all CpG j

```{r calcLambdas}
all_sd_jk <- sapply(rds_list_mat, function(k){
  
  get_sd_k <- function(k){
    ## Calculate a vector of the row (=per CpG j) sd
    return(rowSds(k, na.rm = T))
  }
  ## Return a vector of sds, in a list for each dataset 
  return(get_sd_k(k))
})

## Plot:
df_long <- reshape2::melt(all_sd_jk, variable.name = "Vector", value.name = "SDs")

## Plot distributions of all vectors on the same graph
ggplot(df_long, aes(x = SDs, color = L1)) +
  geom_density() +
  labs(title = "Distribution of SDs accross datasets",
       x = "SDs",
       y = "Density") +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_x_sqrt()

## Calculate lambda per dataset
lambdas = sapply(all_sd_jk, function(x){quantile(x, 0.95, na.rm=T)/median(x, na.rm=T)})
names(lambdas) <- gsub(".95%", "", names(lambdas))
```

```{r}
# Histogram with kernel density
ggplot(data.frame(lambda=lambdas, dataset=names(lambdas)),
       aes(x = lambdas)) +
  geom_histogram(aes(y = after_stat(density)),
                 colour = 1, fill = "white", binwidth = .1) +
  geom_density(lwd = 1, colour = 4,
               fill = 4, alpha = 0.25)+
  theme_minimal() +
  geom_vline(xintercept = median(lambdas), col = "red")

median(lambdas) #1.878303
```

Which datasets have a higher lambda, and why? 

```{r}
df = data.frame(nind=sapply(rds_list_mat, ncol),
                dataset=names(rds_list_mat),
                lambda=lambdas, 
                tissue = sapply(strsplit(names(rds_list_mat), "_"), `[`, 1),
                ethnicity=sapply(strsplit(names(rds_list_mat), "_"), `[`, 2)) %>%
  mutate(dataset=ifelse(dataset %in% c("Blood_Cauc", "Blood_Hisp"), "Blood_Cauc_Hisp", dataset)) %>% 
  mutate(dataset=ifelse(dataset %in% c("Blood_Mexican", "Blood_PuertoRican "), "Blood_Mex_PuertoRican ", dataset)) %>% 
  mutate(dataset=ifelse(dataset %in% c("CD4+_Estonian", "CD8+_Estonian"), "CD4+_CD8+_Estonian", dataset)) %>% 
  mutate(dataset=ifelse(dataset %in% c("Saliva_Hisp", "Saliva_Cauc"), "Saliva_Hisp_Cauc", dataset))

ggplot(data = df,
       aes(x=lambda, y=nind))+
  geom_smooth(method = "lm")+
  geom_point()+
  geom_label_repel(aes(label = dataset, fill=dataset), size= 2, alpha=.8, max.overlaps = 25)+
  theme_bw()+theme(legend.position = "none")+
  scale_x_log10()
```

```{r}
## Emphasize the outliers
df_long$col = "grey"
df_long$col[df_long$L1 %in% "BulkFrontalCortex"] <- "red"

ggplot(df_long, aes(x = SDs, group = L1, fill = col)) +
  geom_density(data = df_long[!df_long$L1 %in% "BulkFrontalCortex",], alpha = .5) +
  geom_density(data = df_long[df_long$L1 %in% "BulkFrontalCortex",], alpha = .6) +
  scale_fill_manual(values = c("grey", "red"))+
  labs(title = "Distribution of SDs accross datasets",subtitle = "Red=BulkFrontalCortex",
       x = "SDs",
       y = "Density") +
  theme_minimal() +
  theme(legend.position = "none") +
  scale_x_sqrt()
```

# Maximum likelihood analysis

The equation is:

$$
\log\left(P(M_j)\right) = \sum_{i=1}^{n} \log\left( \sum_{Z_j=0}^{1} \left( \sum_{Z_{j,k}=0}^{1} P(M_{i,j} \mid Z_{j,k}) \times P(Z_{j,k} \mid Z_j) \right) \times P(Z_j) \right)
$$

## Examine weird values 

The transformation lead to weird values:

```{r investigate_weird_transfo}
test <- readRDS("/mnt/old_user_accounts/p3/maria/PhD/Data/datasets/GEO/Raw_cleaned_beta_matrices_GEO/Blood_Hisp")
test[rownames(test) %in% "cg23089912",5:10]

test <- readRDS("/mnt/old_user_accounts/p3/maria/PhD/Data/datasets/GEO/BMIQ + 10 PCs + age + sex OUTLIERS REMOVED/Blood_Hisp.RDS")
test[rownames(test) %in% "cg23089912",5:10]
# GSM1870986
# 0.00000000000000001124546 --> give extreme value in scaling, and p dnorm=0
```

The zero was weirdly transformed. Is that expected? 

## Optimisation over multiple CpGs

Run on LSHTM server (need to be outside of RStudio for parallelising and h5 files access): 
source("S01_run_hvCpGdetection_Marias.R") ## for different datasets

### "Nelder-Mead" or "L-BFGS-B" optimisation method?

```{r}
## Load data & functions specific to Maria's arrays (to do before)                                                 
system.time(source("../03_prepDatasetsMaria/S02.formatArraysforR.R"))
## Load algorithm (30sec)                                                                                                                                                                                                                 
system.time(source("../05_hvCpGalgorithm/hvCpG_algorithm_detection_v3.R"))

## Load full cpg names
cpg_names <- readLines("~/arraysh5files/sorted_common_cpgs.txt")

length(cpg_names); head(cpg_names)
## [1] 406036
# [1] "cg00000029" "cg00000108" "cg00000109" "cg00000165" "cg00000236" "cg00000289"

## Load hvCpG of Maria and matching mQTL
cistrans_GoDMC_hvCpG_matched_control <- read.table("../03_prepDatasetsMaria/cistrans_GoDMC_hvCpG_matched_control.txt", header = T)

## In which positions are they?
cpg_names[cpg_names %in% cistrans_GoDMC_hvCpG_matched_control$hvCpG_name] %>% length
cpg_names[cpg_names %in% cistrans_GoDMC_hvCpG_matched_control$controlCpG_name]  %>% length

sub_cistrans_GoDMC_hvCpG_matched_control <- cistrans_GoDMC_hvCpG_matched_control[
  cistrans_GoDMC_hvCpG_matched_control$hvCpG_name %in% cpg_names &
    cistrans_GoDMC_hvCpG_matched_control$controlCpG_name %in% cpg_names,]

## Positions of targets in cpg_names:
pos2check <- c(match(sub_cistrans_GoDMC_hvCpG_matched_control$hvCpG_name, cpg_names),
               match(sub_cistrans_GoDMC_hvCpG_matched_control$controlCpG_name, cpg_names))

## Made with "Brent" and new method
load("/home/alice/2024_hvCpG/05_hvCpGalgorithm/resultsDir/Mariads/results_Maria_pos2check_0_8p0_0_65p1.RData")

Brent = data.frame(CpG = cpg_names[as.numeric(row.names(results_Maria_pos2check_0_8p0_0_65p1))],
                   alpha_Brent = as.vector(results_Maria_pos2check_0_8p0_0_65p1))

Brent %>%  
  mutate(ishvCpG = ifelse(CpG %in% Marias_hvCpGs$CpG, "hvCpG in Maria's study", "mQTL matching controls")) %>%
  ggplot(aes(x = ishvCpG, y = alpha_Brent)) +
  geom_jitter(aes(fill=ishvCpG),pch=21, size = 3, alpha = .2)+ 
  geom_violin(aes(col=ishvCpG))+
  geom_boxplot(aes(col=ishvCpG),width = .1) + 
  theme_bw() + theme(legend.position = "none")
```

```{r}
load("/home/alice/2024_hvCpG/05_hvCpGalgorithm/resultsDir/Mariads/withAlpha0.5atStart/results_Nelder_Mead_my_list_mat_Mariads_test3000CpGsvec_0_8p0_0_65p1.RData")
NM = data.frame(CpG = row.names(results_Nelder_Mead_my_list_mat_Mariads_test3000CpGsvec_0_8p0_0_65p1),
                alpha_NM_old = as.vector(results_Nelder_Mead_my_list_mat_Mariads_test3000CpGsvec_0_8p0_0_65p1)) 

NM %>%  
  mutate(ishvCpG = ifelse(CpG %in% Marias_hvCpGs$CpG, "hvCpG in Maria's study", "mQTL matching controls")) %>%
  ggplot(aes(x = ishvCpG, y = alpha_NM_old)) +
  geom_jitter(aes(fill=ishvCpG),pch=21, size = 3, alpha = .2)+ 
  geom_violin(aes(col=ishvCpG))+
  geom_boxplot(aes(col=ishvCpG),width = .05) + 
  theme_bw() + theme(legend.position = "none")
```

```{r}
merge(Brent, NM) %>% 
  mutate(ishvCpG = ifelse(CpG %in% Marias_hvCpGs$CpG, "hvCpG in Maria's study", "mQTL matching controls")) %>% ggplot(aes(x=alpha_Brent, y=alpha_NM_old, fill = ishvCpG)) +
  geom_abline(slope = 1) +
  geom_point(pch=21, size = 3, alpha = .8) +
  theme_bw()
```

The new method is much better than the old one

## ROC curves to define p0 and p1 matching Maria's approach

$$
p0 = P(Z_{j,k}=0 \mid Z_j=0) \\
p1 = P(Z_{j,k}=1 \mid Z_j=1)
$$

p1 = 0.65 in Maria's approach (to be a hvCpG, it needs to be hypervariable in >65% of the datasets)

```{r}
# Step 1: Read results and compute AUC + threshold
files <- list.files(
  "resultsDir/Mariads",
  pattern = "^results_Maria_pos2check_.*\\.RData$",
  full.names = TRUE
)

auc_df <- tibble(p0=double(), p1=double(), AUC=double(), threshold=double())
roc_list <- list()

for (f in files) {
  if (file.info(f)$size == 0) next
  nm <- load(f)
  res <- get(nm)
  
  pstr <- str_match(f, "_(\\d+(?:_\\d+)?)p0_(\\d+(?:_\\d+)?)p1")[, 2:3]
  p0 <- as.numeric(gsub("_", ".", pstr[1]))
  p1 <- as.numeric(gsub("_", ".", pstr[2]))
  label <- sprintf("p0=%.2f p1=%.2f", p0, p1)
  
  df <- as.data.frame(res) %>% rownames_to_column("CpGpos") %>%
    mutate(CpG=cpg_names[as.numeric(CpGpos)])
  colnames(df)[2] <- "alpha"
  
  truth <- ifelse(df$CpG %in% Marias_hvCpGs$CpG, 1, 0)
  roc_obj <- try(roc(truth, df$alpha, quiet=TRUE), silent=TRUE)
  if (inherits(roc_obj, "try-error")) next
  
  aucv <- as.numeric(auc(roc_obj))
  thr <- coords(roc_obj, "best", ret = "threshold", transpose = FALSE)[["threshold"]]
  auc_df <- auc_df %>% add_row(p0, p1, AUC=aucv, threshold=thr)
  pts <- coords(roc_obj, "all", ret=c("sensitivity","specificity"),
                transpose = FALSE) %>%
    as_tibble() %>%
    mutate(FPR = 1 - specificity, TPR = sensitivity, label=label)
  roc_list[[label]] <- pts
}

roc_all <- bind_rows(roc_list)

# Step 2: Plot ROC curves
roc_plot <- ggplot(roc_all, aes(FPR, TPR, group=label, color=label)) +
  geom_line(size=0.8, alpha=0.6) +
  geom_abline(slope=1, linetype="dashed", color="gray50") +
  labs(title="ROC Curves for Different (p0,p1)",
       x="False Positive Rate", y="True Positive Rate") +
  theme_minimal() + theme(legend.position="none")

# Step 3: AUC heatmap with thresholds

### To avoid multiple
auc_df <-   auc_df %>% distinct(p0, p1, .keep_all = TRUE)

best <- auc_df |> 
  filter(AUC == max(AUC, na.rm = TRUE)) |> 
  slice(1)  # in case of ties

heatmap_plot <- ggplot(auc_df, aes(p0, p1, fill=AUC)) +
  geom_tile(color="white") +
  geom_text(aes(label=round(threshold,2)),
            size=3, color="black", check_overlap = TRUE) +
  # Outline best tile
  geom_tile(data = best, aes(p0, p1), fill = NA, color = "red", linewidth = 1.5) +
  scale_fill_viridis_c(option = "plasma") +
  labs(title="AUC & Optimal Threshold per (p0,p1)",
       x="p0", y="p1") +
  theme_minimal()
# Step 4: Show both plots
print(roc_plot)
print(heatmap_plot)
```

The best threshold ploted in tiles is the alpha probability that gives the best sensitivity-specificity trade-off. It's derived using a statistical rule (Youden's J: maximizes (Sensitivity + Specificity – 1), giving the best overall balance between true positives and true negatives). It classifies a CpG as hypervariable in Maria's approach if alpha > threshold 

### Conclusions (NB TO UPDATE WITH NEW ALGO): 

* Best AUC = for p0 (true negative) is quite low in Maria's data (0.45)
* Threshold for this best AUC = : Classify a CpG as hvCpG in Maria's data if alpha ≥ 
* Previous discrepancies between methods are likely due to scaling!

# Subset Maria's data following Atlas data structure (less N/dataset) to check power of detection in Atlas data:          

3 tries for (p0, p1): 

* c(0.45, 0.6): best AUC, closest to Maria's data; low specificity and mid sensitivity                                    * c(0.95, 0.65): our original idea, high specificity but mid sensitivity                                                  * c(0.9, 0.9): high specificity and sensitivity       

```{r}
makeMyPlots <-function(p0p1){
  df1 = get(paste0("results_Nelder_Mead_my_list_mat_Mariads_test3000CpGsvec_", p0p1))
  df2 = get(paste0("results_Nelder_Mead_my_list_mat_Mariads_mimicAtlas_test3000CpGsvec_", p0p1))
  
  p_str = str_match(p0p1, "(\\d+_\\d+)p0_(\\d+_\\d+)p1")[, 2:3]
  p0 = gsub("_", ".", p_str[1])
  p1 = gsub("_", ".", p_str[2])
  label = paste0("p0=", p0, ", p1=", p1)
  
  plot1 = data.frame(df1, df2) %>%
    tibble::rownames_to_column("CpG") %>%
    mutate(ishvCpG = ifelse(CpG %in% MariasCpGs$CpG, "1500 hvCpG in Maria's study", "1500 mQTL matching controls")) %>%
    dplyr::rename(alpha_normalDS = alpha_hat, alpha_mimicAtlas = alpha_hat.1) %>% 
    ggplot(aes(x = alpha_normalDS, y = alpha_mimicAtlas)) +
    geom_point(aes(fill=ishvCpG), pch =21, size =3, alpha = .3) + 
    geom_abline(slope = 1, linetype = "dashed") + theme_bw() +
    ggtitle(label = label)
  
  # === 1) Prepare the ORIGINAL ===
  df_original = df1 %>%
    data.frame() %>%
    tibble::rownames_to_column("CpG") %>%
    mutate(ishvCpG = ifelse(
      CpG %in% MariasCpGs$CpG,
      "1500 hvCpG in Maria's study",
      "1500 mQTL matching controls"
    ),
    source = "original") %>%
    melt()
  
  # === 2) Prepare the MIMIC ===
  df_mimic = df2 %>%
    data.frame() %>%
    tibble::rownames_to_column("CpG") %>%
    mutate(ishvCpG = ifelse(
      CpG %in% MariasCpGs$CpG,
      "1500 hvCpG in Maria's study",
      "1500 mQTL matching controls"
    ),
    source = "mimicAtlas") %>%
    melt()
  
  # === 3) Combine ===
  df_combined = bind_rows(df_original, df_mimic)
  
  # === 4) Plot ===
  plot2 = ggplot(df_combined, aes(x = value, y = ishvCpG, fill = ..x..)) +
    geom_density_ridges_gradient(scale = 3, rel_min_height = .01) +
    facet_wrap(~source, ncol = 1) +
    scale_fill_viridis(name = "alpha", option = "C") +
    theme_bw() +
    theme(axis.title.y = element_blank()) +
    labs(title = "Probability alpha of being hypervariable in my algorithm",
         subtitle = "Original data of Maria vs mimic Atlas structure")
  
  print(plot1)
  print(plot2)
}
```


## 1. low specificity and mid sensitivity (p0=0.45 and p1=0.6)
### best AUC, my algorithm with the closest proximity to Maria's approach)

```{r}
# load("resultsDir/Mariads/withAlpha0.5atStart/results_Nelder_Mead_my_list_mat_Mariads_mimicAtlas_test3000CpGsvec_0_45p0_0_6p1.RData")
# makeMyPlots(p0p1 = "0_45p0_0_6p1")
```

## 2. high specificity and mid sensitivity (p0=0.95 and p1=0.65)
### high true negative rate, i.e. high specificity)

```{r}
# load("resultsDir/results_Nelder_Mead_my_list_mat_Mariads_mimicAtlas_test3000CpGsvec_0_95p0_0_65p1.RData")
# makeMyPlots(p0p1 = "0_95p0_0_65p1")
```

## 3. high specificity and sensitivity (p0=0.9 and p1=0.9)

```{r}
# load("resultsDir/results_Nelder_Mead_my_list_mat_Mariads_mimicAtlas_test3000CpGsvec_0_9p0_0_9p1.RData")
# makeMyPlots(p0p1 = "0_9p0_0_9p1")
```

# Notes:

lambdas are defined based on a 5% threshold, even if alpha is not. How to not hardcode them? MCMC on lambda? Link with alpha?

# The analysis is complete.
